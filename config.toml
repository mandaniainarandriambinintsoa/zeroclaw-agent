# ZeroClaw Configuration - Groq + Render Free Tier
# This config is embedded into the Docker image at build time

workspace_dir = "/zeroclaw-data/workspace"
config_path = "/zeroclaw-data/.zeroclaw/config.toml"

# Groq API key (injected via environment variable at runtime)
api_key = ""

# LLM Provider: Groq - fast model by default, 70B as fallback
default_provider = "groq"
default_model = "llama-3.1-8b-instant"
default_temperature = 0.7

# ── Agent Settings ──────────────────────────────────────────
[agent]
max_tool_iterations = 10

# ── Model Fallback Chain ─────────────────────────────────────
# If llama-3.1-8b-instant is rate-limited, fall back to 70B
[reliability]
fallback_providers = ["groq"]

[reliability.model_fallbacks]
"llama-3.1-8b-instant" = ["llama-3.3-70b-versatile", "llama3-8b-8192"]

# ── Gateway (required for Render) ──────────────────────────
[gateway]
port = 3000
host = "[::]"
allow_public_bind = true
require_pairing = false

# ── Autonomy ───────────────────────────────────────────────
[autonomy]
level = "supervised"
workspace_only = true
allowed_commands = ["git", "npm", "cargo", "ls", "cat", "grep", "find", "echo", "pwd", "wc", "head", "tail"]
forbidden_paths = ["/etc", "/root", "/home", "/usr", "/bin", "/sbin", "/lib", "/opt", "/boot", "/dev", "/proc", "/sys", "/var", "/tmp", "~/.ssh", "~/.gnupg", "~/.aws", "~/.config"]
max_actions_per_hour = 100
max_cost_per_day_cents = 500

# ── Memory (SQLite - lightweight, no external deps) ────────
[memory]
backend = "sqlite"
auto_save = true
embedding_provider = "none"

# ── Web Search (free, no API key needed) ───────────────────
# DuckDuckGo is enabled by default

# ── Channel Timeout (faster for cloud APIs) ────────────────
[channels_config]
cli = true
message_timeout_secs = 60

# ── Telegram Channel ────────────────────────────────────────
# bot_token is injected at runtime via TELEGRAM_BOT_TOKEN env var
[channels_config.telegram]
bot_token = ""
allowed_users = ["8202028798"]
interrupt_on_new_message = true
mention_only = false
